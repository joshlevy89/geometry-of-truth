{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils import collect_acts\n",
    "from generate_acts import load_llama\n",
    "from probes import LRProbe, MMProbe, CCSProbe\n",
    "import plotly.express as px\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/models/llama-2-13B-GPTQ-4bit\n"
     ]
    }
   ],
   "source": [
    "model_size = '13B-2'\n",
    "device = 'cuda:0'\n",
    "\n",
    "tokenizer, model = load_llama(model_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "The Spanish word 'jirafa' means 'giraffe'. This statement is: TRUE\n",
    "The Spanish word 'escribir' means 'to write'. This statement is: TRUE\n",
    "The Spanish word 'diccionario' means 'dictionary'. This statement is: TRUE\n",
    "The Spanish word 'gato' means 'cat'. This statement is: TRUE\n",
    "The Spanish word 'aire' means 'silver'. This statement is: FALSE\"\"\"\n",
    "\n",
    "statement=\"The Spanish word 'hola' means 'goodbye'.\"\n",
    "input_ids = tokenizer(prompt + '\\n' +  statement + ' This statement is:', return_tensors='pt').input_ids.to(device)\n",
    "probs = model(input_ids).logits[0,-1,:].softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0190, device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor(0.9768, device='cuda:0', grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tok = tokenizer.encode('TRUE')[-1]\n",
    "f_tok = tokenizer.encode('FALSE')[-1]\n",
    "\n",
    "probs[t_tok], probs[f_tok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False -> true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "354it [00:18, 18.67it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=diff<br>alpha=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "diff",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "diff",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x",
         "y": [
          -0.45932743533260445
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=tot<br>alpha=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "tot",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "tot",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x",
         "y": [
          0.9937816082330589
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -1,
          1
         ],
         "title": {
          "text": "alpha"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -0.5400557155306969,
          1.0745098884311512
         ],
         "title": {
          "text": "value"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA70AAAFoCAYAAACbsZwZAAAAAXNSR0IArs4c6QAAIABJREFUeF7t3Xm8VuP+//HP3rt5OCkqkZwKkQgnDjqO6XckU3JyzEOIiAynRIlSODQqDTToiKIilCiaZMo8j8fUoYTG3aTa7d9jLd/dsWtn39e6Pnvd6/7cr/3Xz7Gua12f52d9f9f1tvZ975zCwsJC4QcBBBBAAAEEEEAAAQQQQAABgwI5hF6DXaUkBBBAAAEEEEAAAQQQQACBUIDQy4OAAAIIIIAAAggggAACCCBgVoDQa7a1FIYAAggggAACCCCAAAIIIEDo5RlAAAEEEEAAAQQQQAABBBAwK0DoNdtaCkMAAQQQQAABBBBAAAEEECD08gwggAACCCCAAAIIIIAAAgiYFSD0mm0thSGAAAIIIIAAAggggAACCBB6eQYQQAABBBBAAAEEEEAAAQTMChB6zbaWwhBAAAEEEEAAAQQQQAABBAi9PAMIIIAAAggggAACCCCAAAJmBQi9ZltLYQgggAACCCCAAAIIIIAAAoRengEEEEAAAQQQQAABBBBAAAGzAoRes62lMAQQQAABBBBAAAEEEEAAAUIvzwACCCCAAAIIIIAAAggggIBZAUKv2dZSGAIIIIAAAggggAACCCCAAKGXZwABBBBAAAEEEEAAAQQQQMCsAKHXbGspDAEEEEAAAQQQQAABBBBAgNDLM4AAAggggAACCCCAAAIIIGBWgNBrtrUUhgACCCCAAAIIIIAAAgggQOjlGUAAAQQQQAABBBBAAAEEEDArQOg121oKQwABBBBAAAEEEEAAAQQQIPTyDCCAAAIIIIAAAggggAACCJgVIPSabS2FIYAAAggggAACCCCAAAIIEHp5BhBAAAEEEEAAAQQQQAABBMwKEHrNtpbCEEAAAQQQQAABBBBAAAEECL08AwgggAACCCCAAAIIIIAAAmYFCL1mW0thCCCAAAIIIIAAAggggAAChF6eAQQQQAABBBBAAAEEEEAAAbMChF6zraUwBBBAAAEEEEAAAQQQQAABQi/PAAIIIIAAAggggAACCCCAgFkBQq/Z1lIYAggggAACCCCAAAIIIIAAoZdnAAEEEEAAAQQQQAABBBBAwKwAoddsaykMAQQQQAABBBBAAAEEEECA0MszgAACCCCAAAIIIIAAAgggYFaA0Gu2tRSGAAIIIIAAAggggAACCCBA6OUZQAABBBBAAAEEEEAAAQQQMCtA6DXbWgpDAAEEEEAAAQQQQAABBBAg9PIMIIAAAggggAACCCCAAAIImBUg9JptLYUhgAACCCCAAAIIIIAAAggQenkGEEAAAQQQQAABBBBAAAEEzAoQes22lsIQQAABBBBAAAEEEEAAAQQIvTwDCCCAAAIIIIAAAggggAACZgUIvWZbS2EIIIAAAggggAACCCCAAAKEXp4BBBBAAAEEEEAAAQQQQAABswKEXrOtpTAEEEAAAQQQQAABBBBAAAFCL88AAggggAACCCCAAAIIIICAWQFCr9nWUhgCCCCAAAIIIIAAAggggAChl2cAAQQQQAABBBBAAAEEEEDArACh12xrKQwBBBBAAAEEEEAAAQQQQIDQyzOAAAIIIIAAAggggAACCCBgVoDQa7a1FIYAAggggAACCCCAAAIIIEDo5RlAAAEEEEAAAQQQQAABBBAwK0DoNdtaCkMAAQQQQAABBBBAAAEEECD08gwggAACCCCAAAIIIIAAAgiYFSD0mm0thSGAAAIIIIAAAggggAACCBB6eQYQQAABBBBAAAEEEEAAAQTMChB6zbaWwhBAAAEEEEAAAQQQQAABBAi9PAMIIIAAAggggAACCCCAAAJmBQi9ZltLYQgggAACCCCAAAIIIIAAAoRez2dg8bL1njMwHAEbAtUrlxPJyZH8dZtsFEQVCHgI7LZz5XA0e4QHIkPNCLA/mGklhSgJFO0RStMxTQoChN4UkH7vEg40noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClAQIvUqQDtMQeh2wSrqU0OsJyHAzAhxqzLSSQhQECL0KiExhRoD9wUwrKURJgNCrBOkwDaHXAYvQ64nFcNMCHGpMt5fiHAUIvY5gXG5agP3BdHspLoIAoTcCmucQQm+KgIWFhVKwZYuUy8srNoI3vSkCcpl5AQ415ltMgQ4ChF4HLC41L8D+YL7FFOgoQOh1BFO4nNCbIuK0Wa/IoFGTZc7kQYTeFM24LLsEONRkV7+p9vcFCL08IQj8T4D9gacBgeIChN74nwhCbynmi75fKh269JfvlvwkdWvXJPTG/4xyxwwR4FCTIY1imbEIEHpjYeYmGSLA/pAhjWKZsQkQemOj3nojQm8p5psLCuTn5atkzkvvyOgJ0wm98T+j3DFDBDjUZEijWGYsAoTeWJi5SYYIsD9kSKNYZmwCmRB6Z857Q/5QrYoc0WL/lFwmPjlb3nj3UxnYq9MOr7+t/4Oy+667yOXnn5rSnJoXEXpT1Hx2zkLpN+JRQm+KXlyWfQIcarKv51S8YwFCL08HAv8TYH/gaUCguEAmhN7jzrxe9tt7Txl253UptW/g/ZMkCMozJ/bb4fXnXNVH9vrj7tLnxktSmlPzIkJvipo7Cr0r8jemOAOXIWBboFKFXJGcHNnwS4HtQqkOgSKBnB1T1KxWIfyXK9awR2TtA1OYtZVvVzj7A88CAsUFalb/dY9I8s/qNeskLzdXqlaplNIyCb0pMSX/oh2F3nW/bE7+4lkhAjEIlM/LDe+yqWBLDHfjFggkQOB3Qk2VSuXCBa7bwB6RgE6lZwm/8x9F0rOg9N2V/SF99tw5mQJVKv66R/j+9Oo/TnJyc+S2Gy7aOlXw0cyruw+Wo/58oJx3xt/khl7D5aPPvg6/n6jWTtWl5WEHyPUdzgy/qyj46XnPWGnYYFfZu2F9Cb6498dlK+XePtfI4FFTZLe6O0uH804Jrxv32HMyadpc+WnZqvCfm+/fWK655Axp3rRx+M9B6J367AK59NyT5YlnXpQvv10sx7U8WHp1aS871/xDeM22b3oLCrbIw088L49Pnx9ev0+j+tLxwjbS6phDfWm2G8+b3hRJ+fXmFKG4LGsF+PW1rG09hZcgwK8381gg8D8B9geeBgSKC2j9evOEqbPljnvHh79SXL9e7fAmL7/xoVzetb9MGN4zDKSdew6Rg/bfS+rXqyMrVq6W+x6cKk32aiCj+3cNr2/X4Tb55Itvw//3MUceJHl5udKn66XS8aaBxX4VeejYJyQIqfs02kMKCgrk4cefl68WLZG5UwZJtaqVw9A7ZuIM2bN+XWnb+qgwxAYhuuWhzeSBfl1KDL3BmIlPzpFzTj9ODmzaWJ6b+7oEmato7ZrPDaG3FM3g7/Nu3lwQNiH4k0UzJ/QL/4tK0d/r5e/0aj6OzJXJAhxqMrl7rF1bgNCrLcp8mSzA/pDJ3WPtZSGgFXpXrV4rR57WSTq1bytXXdQmXGrwZvfrRYtl6ti+xZb+y8ZNsmJVvoyfPEvGTXpO3p89Ngy4QegtX75c+Nnd4E1w0c+OPn8bvEleuWpN+KVVXW4fIROH9wwDa9Gb3uDPuwbzBT/DHpwqw//9lLwwaaDUq1Or2JveZStWy1/bdpYbrviHXHrOSeH1wdxHnNJJ/n7yX+Wmq89VpSf0lsL5n6+/lzbtexS76tQTjpR/db88/N8IvarPI5NlsACHmgxuHktXFyD0qpMyYQYLsD9kcPNYepkIaIXeYHE9/jVaXnztPZn7+GBZnb9Ojjr9GunV5WI585RjwrXPnPe6jHzoafn8q++K1fLu86PDcBqE3gP2a1TsV6SDC7cNvZ/+Z5H0H/mYvPrmR8XmeXDQTXLYwfuGoXfbL7JasPB96dhtoIwf2kMOOWDvYnO++d5nctG1d4VvqKtXq7J1zuCtc/DGOdUv0Eq1QYTeVKV2cB2h1xOQ4WYEONSYaSWFKAgQehUQmcKMAPuDmVZSiJKAZuh958Mv5Pyr75CRd98gi75fKncOeUQWPjMi/JXjol91Pv3Ev8hZpx0r9XerI7NfekuCzwK7hN5V+WvlyFM7hW90O19yhjTaczdZvWatnN7+Fvm90Dv/1ffkqpsHycP39ZCDmxUPvQsWfiAduw2Q7p3Plwa71ykmu1ON6nLAvg2VtH+dhtDryUno9QRkuBkBDjVmWkkhCgKEXgVEpjAjwP5gppUUoiSgGXqDJZ12UfcwiH717WJpcdC+cuv1F4YrDb6MatQj0+XdF8ZI+XJ54f8WfNnULXePcQq9RQG1KLwG8wQBu/V53X439N4zbKL8e/JMWfDk0PBXp3/79njR9z9K6/NuDN8w/+O0Y4vJBh8vzcnR/TZAQq/nw0vo9QRkuBkBDjVmWkkhCgKEXgVEpjAjwP5gppUUoiSgHXoffWqO9Bn0ULi6KaN6h39fN/gpetPa9cqzpcVBTeTjz76R4Auplq/Mdwq9wfXBr023adVSzm5znCz9eYXcP35a+AVYv33TG3wp1cBenaR+vV1k9ktvh9cce+RBck/PjuF6tv2V6eBLtmYveFt6d2kvfzpwHwk+5xv8qnZubq5c16Gdkvav0xB6PTkJvZ6ADDcjwKHGTCspREGA0KuAyBRmBNgfzLSSQpQEtENv0a8fN2vSUB67/7atqwy+GKr7naPkmdmvhf9b8LY1+CbnOS+/szX0nnVFb2na5I+lfqY3+JNFw8Y9KevWbwjnCn5l+snnXpJxg2+SQw/aVwY9MFlGT3hGqlSutPWavx7ePPwepBp/qFpi6A3WHbyNnvT03K1rDtYY/Mpz6+P+rKRN6FWBJPSqMDKJAQEONQaaSAlqAoReNUomMiDA/mCgiZSgKqAdektbXPAtz6vy18juu9YOv7E56k/wDdCLf/hZdq2zs1SuVKHEaTZt2iyLly4LP1Nc9Pd5S7tfEM5/+nmlVKpUQWrW+N83SJc2zuXf86bXRauEawm9noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClATiDr1Ky87oaQi9nu0j9HoCMtyMAIcaM62kEAUBQq8CIlOYEWB/MNNKClESIPQqQTpMQ+h1wCrpUkKvJyDDzQhwqDHTSgpRECD0KiAyhRkB9gczraQQJQFCrxKkwzSEXgcsQq8nFsNNC3CoMd1einMUIPQ6gnG5aQH2B9PtpbgIAoTeCGieQwi9noC86fUEZLgZAQ41ZlpJIQoChF4FRKYwI8D+YKaVFKIkQOhVgnSYhtDrgMWbXk8shpsW4FBjur0U5yhA6HUE43LTAuwPpttLcREECL0R0DyHEHo9AXnT6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREmA0KsE6TANodcBize9nlgMNy3AocZ0eynOUYDQ6wjG5aYF2B9Mt5fiIggQeiOgeQ4h9HoC8qbXE5DhZgQ41JhpJYUoCBB6FRCZwowA+4OZVlKIkkC2hd4tWwrlubmvS8vDmkmN6lVlwy8bJS83V8qXLxeKbtpcIK+99bEsX7la/t9Rf5KqVSrJR599I59/9V9p0byJ7LFbHW95Qq8nIaHXE5DhZgQ41JhpJYUoCBB6FRCZwowA+4OZVlKIkkC2hd5NmzbLQX+7TKaM6i377b2nnH/1HXLgfo3kxk7nyOaCAjnh7C5SrUpl2bN+Xbn5mvNkyNgn5OXXP5A/HdhETmvVUo5rebC3PKHXk5DQ6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREkg20Pv14uWSOXKFWXX2rXkjXc/latuHiyvTR8ueXm5sm79Bjm0dUeZOrav7NOovpK4CKHXk5LQ6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREkgG0Lvq29+JHcNfUS+/HaxHNi0sbz/8Zdb3/TeM2yi7NVwdzn8kKZy/jV3yNKfVkizJg1l/30byhdffSdvf/B5+EY4+BXoiSNuldzcHG95Qq8nIaHXE5DhZgQ41JhpJYUoCBB6FRCZwowA+4OZVlKIkoB26F2zVuT7xYVKq0t9murVRHart30g/e/iH+XEc2+UNq1aSrtTjpEfflwuXfuM2Bp6O3UfLAfu11guPLOVDB3zuMx+6W3p2+1SqV6tinz17ZLw2uF3XR9+tjf4TK/GD6HXU5HQ6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspRElAO/S+/V6hDB+7WWl1qU9zyIE5ctWlv34Z1W9/7h8/TR5+fJa8OHWI5OTkyLaf6S0KvVdccKpMmT5fJk+bJ4/df1s4xVeLlsipF94sC58ZIdWqVk59MaVcSej1pCT0egIy3IwAhxozraQQBQFCrwIiU5gRYH8w00oKURLQDr2ff1koT80oUFpd6tPs3ThHTj8pb7sBt9w9RjZu3CT39OwY/jtCb+qmib2S0JvY1rCwmAU41MQMzu0SLUDoTXR7WFzMAuwPMYNzu8QLaIfepBX878kz5fn5b8rD9/Ug9CatOVHXQ+iNKsc4awIcaqx1lHp8BAi9PnqMtSbA/mCto9TjK2A99H76n0Xy98tulX49r5TDDt5Xpj//qvQb8eh2n+nl15t9n6QYxxN6Y8TmVokW4FCT6PawuJgFCL0xg3O7RAuwPyS6PSwuDQLWQ++WLYVyY9+R8uychaHuMUceJPNeeVceH3277LtXA7mmx71ywH6N5PLzT5XHn3lRJj09d+tneoM/Z3TKhTfL6zNGhl9kpfXDZ3o9JQm9noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClASsh94ipp+Xr5Ly5ctJjepVleSiT0PojW4XjiT0egIy3IwAhxozraQQBQFCrwIiU5gRYH8w00oKURLIltCrxKUyDaHXk5HQ6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREmA0KsE6TANodcBq6RLCb2egAw3I8ChxkwrKURBgNCrgMgUZgTYH8y0kkKUBAi9SpAO0xB6HbAIvZ5YDDctwKHGdHspzlGA0OsIxuWmBdgfTLeX4iIIEHojoHkOIfR6AvKm1xOQ4WYEONSYaSWFKAgQehUQmcKMAPuDmVZSiJIAoVcJ0mEaQq8DFm96PbEYblqAQ43p9lKcowCh1xGMy00LsD+Ybi/FRRAg9EZA8xxC6PUE5E2vJyDDzQhwqDHTSgpRECD0KiAyhRkB9gczraQQJQFCrxKkwzSEXgcs3vR6YjHctACHGtPtpThHAUKvIxiXmxZgfzDdXoqLIEDojYDmOYTQ6wnIm15PQIabEeBQY6aVFKIgQOhVQGQKMwLsD2ZaSSFKAoReJUiHaQi9Dli86fXEYrhpAQ41pttLcY4ChF5HMC43LcD+YLq9FBdBwHro/W7JTzLw/klyT8+OUi4vr1Qh1+tLnbCECwi9UdR+M4Y3vZ6ADDcjwKHGTCspREGA0KuAyBRmBNgfzLSSQpQErIfeT774Vtp1uE3efX60lC9frlQ11+tLnZDQG4Xo98cQevVNmTEzBTjUZGbfWHXZCBB6y8aVWTNTgP0hM/vGqstOwHroDQJvEGT323tPycvNle7Xni/NmjSUsY/OkIlPzpb8Nevl+KMOkZuvPk9q/KFqGJC3vb5508aqDeBNrycnodcTkOFmBDjUmGklhSgIEHoVEJnCjAD7g5lWUoiSgHboLVy9Ugr++5XS6lKfJvcPNSV3j4bbDZj67AK55e4xMrp/VylXLk/2abyHzJr/htwz7FHpetXZUq9OLbl39OOy2647y5A+naWk62tUr5r6QlK4ktCbAtLvXULo9QRkuBkBDjVmWkkhCgKEXgVEpjAjwP5gppUUoiSgHXo3LZwvawf0UFpd6tOUP+xoqdrlju0GlPTryudc1Uf23auB3HbDReH1Lyx4S67tOVReeXqYLF76s9OvQ6e+wv9dSeiNovabMYReT0CGmxHgUGOmlRSiIEDoVUBkCjMC7A9mWkkhSgLaoXfzJ+/JhsdGK60u9WnK7ddcKp11WUqh96jTr5EbrviHtG19VHj9kqXL5P+d9U95Ykwf2bJlC6E3dfb0XEnoTY87d02eAIea5PWEFaVPgNCbPnvunDwB9ofk9YQVpVdAO/Smt5rt7/7pfxbJ3y+7Vd6eNUoqVigfXtD2kluk5WEHSJeOZ4X//OqbH8llXfrJ3CmDZfnK1dtdr10Tb3o9RQm9noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClASsh971GzZKixMvl7GDusmB+zWWwsJCGTtxhjzx7IsyuPfVUrd2Lek7+CFZ8uNymfxAL9nwy6btrq9SuaKS9q/TEHo9OQm9noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClASsh96A6b6xU2XEQ0+FYsEXWjXfv7F0v2u0PP/im+H/tmf9ujK0b2dp/Mfdw3/e9vojWuyvpE3oVYEk9KowMokBAQ41BppICWoChF41SiYyIMD+YKCJlKAqkA2hNwAL3vhu3LRJfvtNzKvy18qGDRulbu2a25mWdL0WPG96PSUJvZ6ADDcjwKHGTCspREGA0KuAyBRmBNgfzLSSQpQEsiX0KnGpTEPo9WQk9HoCMtyMAIcaM62kEAUBQq8CIlOYEWB/MNNKClESIPQqQTpMQ+h1wCrpUkKvJyDDzQhwqDHTSgpRECD0KiAyhRkB9gczraQQJQFCrxKkwzSEXgcsQq8nFsNNC3CoMd1einMUIPQ6gnG5aQH2B9PtpbgIAoTeCGieQwi9noC86fUEZLgZAQ41ZlpJIQoChF4FRKYwI8D+YKaVFKIkQOhVgnSYhtDrgMWbXk8shpsW4FBjur0U5yhA6HUE43LTAuwPpttLcREECL0R0DyHEHo9AXnT6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREmA0KsE6TANodcBize9nlgMNy3AocZ0eynOUYDQ6wjG5aYF2B9Mt5fiIggQeiOgeQ4h9HoC8qbXE5DhZgQ41JhpJYUoCBB6FRCZwowA+4OZVlKIkgChVwnSYRpCrwMWb3o9sRhuWoBDjen2UpyjAKHXEYzLTQuwP5huL8VFECD0RkDzHELo9QTkTa8nIMPNCHCoMdNKClEQIPQqIDKFGQH2BzOtpBAlAUKvEqTDNIReByze9HpiMdy0AIca0+2lOEcBQq8jGJebFmB/MN1eiosgQOiNgOY5hNDrCcibXk9AhpsR4FBjppUUoiBA6FVAZAozAuwPZlpJIUoChF4lSIdpCL0OWLzp9cRiuGkBDjWm20txjgKEXkcwLjctwP5gur0UF0GA0BsBzXMIodcTkDe9noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClAQIvUqQDtNkbejduHGTrFi1RursspPk5OQ4kBW/lNAbmY6BxgQ41BhrKOV4CRB6vfgYbEyA/cFYQynHW4DQ603oPEHWhd7CwkIZ8dDTMuzBqSFWrZ2qy313XifNmzYuEW/2grelc88h2/27t2eNkooVyguh1/mZY4BRAQ41RhtLWZEECL2R2BhkVID9wWhjKSuyAKE3Ml3kgVkXet/58As5/+o7ZPzQ7nLAvo1kyJgn5JnZr8oLjw2U3Nzt3/i+sOAtufnOUTJlVO9iyA12rxO+ISb0Rn72GGhMgEONsYZSjpcAodeLj8HGBNgfjDWUcrwFCL3ehM4TZF3oHTByknzyn29ldP+uIdaPP6+UY9tdF4ba/fbeczvAIPT2HjBOFjw5tERcQq/zM8cAowIcaow2lrIiCRB6I7ExyKgA+4PRxlJWZAFCb2S6yAOzLvR2uX2E1KxRTXpce8FWtP2PuViG33W9HH1E8xJD77U9h0qbVi2lYsUK0qJ5E2l1zKFSLi8vvJbQG/nZY6AxAQ41xhpKOV4ChF4vPgYbE2B/MNZQyvEWIPR6EzpPkHWh9/Ku/aVJ4wbyz47/2Ip1aOuO0qvLxXLy8YdvB/jBp1/LzHmvS43qVWXx0mUy6em5cm7b47eG5p9X/eKMzgAELApUqZgnkiOybkOBxfKoCQEngV1qVAyvZ49wYuNiowLsD0YbS1mRBYr2iMgTMNBZIOtCb/CmN/jyqu6dz9+K9XtvercVfWLGi9LznrHy3uwx4dveXzZxwHd+6hhgUiAv/Ex8jhRs2WKyPopCwEWgYvlffxuIPcJFjWutCrA/WO0sdUUVKNojoo5nnLtA1oXe4DO9n325SB7o1yXUKu0zvduSLlj4gXTsNkDemvmAVKpYgV9vdn/mGGFUgF9fM9pYyookwK83R2JjkFEB9gejjaWsyAL8enNkusgDsy70/u/bm3vIAfs1kntHT5EZs1/b+u3N4yY9J8GfKQq+3Tn4mTB1tjRpvIc03eePsip/jXS9faSUL5cnYwd1C/89n+mN/Owx0JgAhxpjDaUcLwFCrxcfg40JsD8YayjleAsQer0JnSfIutAb/J3e+x6cKiMfejrEqlK5kjzQ759ycLO9w3/uN/xRmTRtnrzx7MjwnwfeP0nGTJyxFfbApo2lX8+OUr9ebUKv8+PGAMsCHGosd5faXAUIva5iXG9ZgP3BcnepLYoAoTeKmt+YrAu9RVwbftkoy1esll3r7Fzi3+f9LWtw7U/LVkr1qlVkpxrVionzptfvAWS0HQEONXZ6SSX+AoRef0NmsCPA/mCnl1SiI0Do1XF0mSVrQ68L0u9dS+jVkmSeTBfgUJPpHWT9mgKEXk1N5sp0AfaHTO8g69cWIPRqi5Y+H6G3dKPfvYLQ6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREmA0KsE6TANodcBq6RLCb2egAw3I8ChxkwrKURBgNCrgMgUZgTYH8y0kkKUBAi9SpAO0xB6HbAIvZ5YDDctwKHGdHspzlGA0OsIxuWmBdgfTLeX4iIIEHojoHkOIfR6AvKm1xOQ4WYEONSYaSWFKAgQehUQmcKMAPuDmVZSiJIAoVcJ0mEaQq8DFm96PbEYblqAQ43p9lKcowCh1xGMy00LsD+Ybi/FRRAg9EbjQJGNAAAgAElEQVRA8xxC6PUE5E2vJyDDzQhwqDHTSgpRECD0KiAyhRkB9gczraQQJQFCrxKkwzSEXgcs3vR6YjHctACHGtPtpThHAUKvIxiXmxZgfzDdXoqLIEDojYDmOUQ99K7fsFHKlcuT8uXyPJeWGcN505sZfWKVZS/AoabsjblD5ggQejOnV6y07AXYH8remDtklgChN/5+qYTezQUF8sDD02Xi1Bdk+cp8+Vf3y+XUE46Ujt0GSIUK5WVIn87xVxbTHQm9MUFzm8QLcKhJfItYYIwChN4YsblV4gXYHxLfIhYYswChN2ZwEVEJvfNeeVc6dR8sZ5z0V3n9nU/k6vZtw9A7a/6bcv1t98kr04ZJjepV468uhjsSemNA5hYZIcChJiPaxCJjEiD0xgTNbTJCgP0hI9rEImMUIPTGiP1/t1IJvcEb3T12qyM9rr1ALu/aX07925Fh6P3hp+Vy/Jk3yJRRvWW/vfeMv7oY7kjojQGZW2SEAIeajGgTi4xJgNAbEzS3yQgB9oeMaBOLjFGA0BsjtmboPe7M6+XKi9rImaccU2Loffrfd0rjPXeLv7oY7kjojQGZW2SEAIeajGgTi4xJgNAbEzS3yQgB9oeMaBOLjFGA0Bsjtmbove7W+2Tl6jUydmC38HO8RW96h4x5XO4fP03enjVKKlYoH391MdyR0BsDMrfICAEONRnRJhYZkwChNyZobpMRAuwPGdEmFhmjAKE3RmzN0PvZl/+VMy7tKXvWryv5a9bJQfvvJZsLtsiLr70n13VoJx3OOyX+ymK6I6E3Jmhuk3gBDjWJbxELjFGA0BsjNrdKvAD7Q+JbxAJjFiD0xgyu9UVWwbKD4Bu82X39nU9l3foNsk+j+nLeGX8Lv9wqNzcn/spiuiOhNyZobpN4AQ41iW8RC4xRgNAbIza3SrwA+0PiW8QCYxYg9MYMrhl6f7v0wsJCycmxG3R/WyuhN/6HljsmU4BDTTL7wqrSI0DoTY87d02mAPtDMvvCqtInQOiN317l25u//HaxrM5fu8PVH7BfIymXlxd/dTHckdAbAzK3yAgBDjUZ0SYWGZMAoTcmaG6TEQLsDxnRJhYZowChN0bs/7uVSui9pse9Mufld3a4ev5Ob/yN5Y4IxC3AoSZuce6XZAFCb5K7w9riFmB/iFuc+yVdgNAbf4dUQu+Spctk7boN262+x79Gyx6715G7e1wheXm58VcXwx150xsDMrfICAEONRnRJhYZkwChNyZobpMRAuwPGdEmFhmjAKE3RmzNN707WvaChe9Lx24D5bXpw6V6tSrxVxfDHQm9MSBzi4wQ4FCTEW1ikTEJEHpjguY2GSHA/pARbWKRMQoQemPEjiP0Lvp+qbQ+r5s8OvI2OWDfhvFXF8MdCb0xIHOLjBDgUJMRbWKRMQkQemOC5jYZIcD+kBFtYpExChB6Y8TWDL0/LVsp6zf8Umz1+WvWy4SpL8is+W/Ki1OHSOVKFeKvLoY7EnpjQOYWGSHAoSYj2sQiYxIg9MYEzW0yQoD9ISPaxCJjFCD0xoitGXp39EVWVSpXks6XniEXtDsh/spiuiOhNyZobpN4AQ41iW8RC4xRgNAbIza3SrwA+0PiW8QCYxYg9MYMrvV3ej/78r+yYmV+sdVXrVJJ9ttnT7N/qqioWEJv/A8td0ymAIeaZPaFVaVHgNCbHnfumkwB9odk9oVVpU+A0Bu/vcq3N8e/7OTckdCbnF6wkvQKcKhJrz93T5YAoTdZ/WA16RVgf0ivP3dPngChN/6eRA69wd/l/W7xjymt+Kw2x0nFCuVTujbTLiL0ZlrHWG9ZCXCoKStZ5s1EAUJvJnaNNZeVAPtDWckyb6YKEHrj71zk0HtDr+Eyc97rKa34lWnDpEb1qildm2kXEXozrWOst6wEONSUlSzzZqIAoTcTu8aay0qA/aGsZJk3UwUIvfF3LnLojX+pybwjoTeZfWFV8QtwqInfnDsmV4DQm9zesLL4Bdgf4jfnjskWIPTG3x9Cr6c5odcTkOFmBDjUmGklhSgIEHoVEJnCjAD7g5lWUoiSAKFXCdJhGrXQ+/IbH8ob734qa9et3+72N1xxFn+n16EpXIpAJgpwqMnErrHmshIg9JaVLPNmogD7QyZ2jTWXpQChtyx1S55bJfQ+M/s1ubHPSAn+Lu+69Rtkz/p1wy+u+vyr76TWTtXl2UfukWpVK8dfXQx35E1vDMjcIiMEONRkRJtYZEwChN6YoLlNRgiwP2REm1hkjAKE3hix/+9WKqH34uv+FYbb2/55sRx5aid5/tH+stuuu8jgUVNk4TufyMThPeOvLKY7EnpjguY2iRfgUJP4FrHAGAUIvTFic6vEC7A/JL5FLDBmAUJvzOAiohJ6W53TVTqcd4qccdJf5YDj2suE4T2ledPG4ZvetpfcItMfuksaNqgXf3Ux3JHQGwMyt8gIAQ41GdEmFhmTAKE3JmhukxEC7A8Z0SYWGaMAoTdGbM03vadd1F3atj5K2p/dWtp1uE1aH/dnufSck+Tjz7+RMy/vJY+OuFUO2K9R/NXFcEdCbwzI3CIjBDjUZESbWGRMAoTemKC5TUYIsD9kRJtYZIwChN4YsTVDb6fug8Ppht15nQz/91My7MGpcuGZreS1tz6Sn5evkrmPD5ZyeXnxVxfDHQm9MSBzi4wQ4FCTEW1ikTEJEHpjguY2GSHA/pARbWKRMQoQemPE1gy9n3zxrfz480o5+ojmsnHjJunZb6xMf/5VOeSAfeSqi9rIES32j7+ymO5I6I0JmtskXoBDTeJbxAJjFCD0xojNrRIvwP6Q+BaxwJgFCL0xg2t9pnfJj8tl19o1JScnZ2sFW7YUSm7u//45/tLiuSOhNx5n7pJ8AQ41ye8RK4xPgNAbnzV3Sr4A+0Pye8QK4xUg9MbrHdxN5Yusrulxr3z73VI5p+3xctLxh0uN6lXjryRNdyT0pgme2yZOgENN4lrCgtIoQOhNIz63TpwA+0PiWsKC0ixA6I2/ASqh9+0PPpeHH39eZs57I6yg3SlHS7uTjzb75VW/bROhN/6HljsmU4BDTTL7wqrSI0DoTY87d02mAPtDMvvCqtInQOiN314l9BYte9mK1TJj9msy8cnZ4ZvffRrVl/PO+Juc3vovfJFV/L3ljgjEKsChJlZubpZwAUJvwhvE8mIVYH+IlZubZYAAoTf+JqmG3qLlB5/nHTfpWRkwclL4P70ybZjZX3nmTW/8Dy13TKYAh5pk9oVVpUeA0Jsed+6aTAH2h2T2hVWlT4DQG7+9augN/jxR8Kb30afmhG9669auGb7pDf58Ufly/Mmi+NvLHRGIT4BDTXzW3Cn5AoTe5PeIFcYnwP4QnzV3ygwBQm/8fVIJvW9/8IU8/PisrZ/p/dtfW8iZpx4jhx/SVPLycuOvKsY78qY3RmxulWgBDjWJbg+Li1mA0BszOLdLtAD7Q6Lbw+LSIEDojR9dJfQG39780effyDmnHy9tWv1F6uyyU/yVpOmOhN40wXPbxAlwqElcS1hQGgUIvWnE59aJE2B/SFxLWFCaBQi98TdAJfR+vWiJNNi9rvm3uiW1h9Ab/0PLHZMpwKEmmX1hVekRIPSmx527JlOA/SGZfWFV6RMg9MZvrxJ64192cu5I6E1OL1hJegU41KTXn7snS4DQm6x+sJr0CrA/pNefuydPgNAbf08IvZ7mhF5PQIabEeBQY6aVFKIgQOhVQGQKMwLsD2ZaSSFKAoReJUiHaQi9DlglXUro9QRkuBkBDjVmWkkhCgKEXgVEpjAjwP5gppUUoiRA6FWCdJiG0OuARej1xGK4aQEONabbS3GOAoReRzAuNy3A/mC6vRQXQYDQGwHNcwih1xOQN72egAw3I8ChxkwrKURBgNCrgMgUZgTYH8y0kkKUBAi9SpAO0xB6HbB40+uJxXDTAhxqTLeX4hwFCL2OYFxuWoD9wXR7KS6CAKE3AprnEEKvJyBvej0BGW5GgEONmVZSiIIAoVcBkSnMCLA/mGklhSgJEHqVIB2mIfQ6YPGm1xOL4aYFONSYbi/FOQoQeh3BuNy0APuD6fZSXAQBQm8ENM8hhF5PQN70egIy3IwAhxozraQQBQFCrwIiU5gRYH8w00oKURIg9CpBOkxD6HXA4k2vJxbDTQtwqDHdXopzFCD0OoJxuWkB9gfT7aW4CAKE3ghonkMIvZ6AvOn1BGS4GQEONWZaSSEKAoReBUSmMCPA/mCmlRSiJEDoVYJ0mIbQ64DFm15PLIabFuBQY7q9FOcoQOh1BONy0wLsD6bbS3ERBAi9EdA8hxB6UwTMX7NONhcUSM0a1YuN4E1vioBcZl6AQ435FlOggwCh1wGLS80LsD+YbzEFOgoQeh3BFC4n9JaCuG79BunW936Z8/I74ZUHNm0sQ/t2ll1q1Qj/mdCr8BQyhQkBDjUm2kgRSgKEXiVIpjEhwP5goo0UoShA6FXETHEqQm8pUKMnPCOTp82T8UN7SOVKFeTKmwZJwwb1pM+NlxB6U3zIuCw7BDjUZEefqTI1AUJvak5clR0C7A/Z0WeqTF2A0Ju6ldaVhN5SJNt1uE1aHXOodDjvlPDKmfNelxt6DZcP5z4oOTk5vOnVehKZJ+MFONRkfAspQFGA0KuIyVQZL8D+kPEtpABlAUKvMmgK0xF6S0E6tHVH6dvt0jD4Bj8ff/6NnHl5L3ll2jCpUb2q5K/blAIzlyBgX6BC+VwRyZGNmwrsF0uFCJQiUL1K+fAK9ggeFQRE2B94ChAoLlC0R+ASnwCh93esCwsLpdmx7WX4XdfL0Uc0D6/88pvv5bSLe8gLjw2QenV3jq9T3AkBBBBAAAEEEEAAAQQQQMBZgNBbClnwpveOmy6TE45uEV7Jm17nZ4wBWSLAf8nPkkZTZkoCvOlNiYmLskSA/SFLGk2ZKQvwpjdlKrULCb2lUAaf6T3x2MPksnNPDq/kM71qzx4TGRPgM1vGGko5XgJ8pteLj8HGBNgfjDWUcrwF+EyvN6HzBITeUshGPTJdpkyfH357c5XKFaVjt4F8e7PzY8aAbBDgUJMNXabGVAUIvalKcV02CLA/ZEOXqdFFgNDroqVzLaG3FMe16zZIl9tHyIuvvRde2axJQxl6x7VSZ5edwn/m7/TqPIjMkvkCHGoyv4dUoCdA6NWzZKbMF2B/yPweUoGuAKFX1zOV2Qi9qSiJyKr8tbJp02bZpVaNYiMIvSkCcpl5AQ415ltMgQ4ChF4HLC41L8D+YL7FFOgoQOh1BFO4nNDriUjo9QRkuBkBDjVmWkkhCgKEXgVEpjAjwP5gppUUoiRA6FWCdJiG0OuAVdKlhF5PQIabEeBQY6aVFKIgQOhVQGQKMwLsD2ZaSSFKAoReJUiHaQi9DliEXk8shpsW4FBjur0U5yhA6HUE43LTAuwPpttLcREECL0R0DyHEHo9AXnT6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREmA0KsE6TANodcBize9nlgMNy3AocZ0eynOUYDQ6wjG5aYF2B9Mt5fiIggQeiOgeQ4h9HoC8qbXE5DhZgQ41JhpJYUoCBB6FRCZwowA+4OZVlKIkgChVwnSYRpCrwMWb3o9sRhuWoBDjen2UpyjAKHXEYzLTQuwP5huL8VFECD0RkDzHELo9QTkTa8nIMPNCHCoMdNKClEQIPQqIDKFGQH2BzOtpBAlAUKvEqTDNIReByze9HpiMdy0AIca0+2lOEcBQq8jGJebFmB/MN1eiosgQOiNgOY5hNDrCcibXk9AhpsR4FBjppUUoiBA6FVAZAozAuwPZlpJIUoChF4lSIdpCL0OWLzp9cRiuGkBDjWm20txjgKEXkcwLjctwP5gur0UF0GA0BsBzXMIodcTkDe9noAMNyPAocZMKylEQYDQq4DIFGYE2B/MtJJClAQIvUqQDtMQeh2weNPricVw0wIcaky3l+IcBQi9jmBcblqA/cF0eykuggChNwKa5xBCrycgb3o9ARluRoBDjZlWUoiCAKFXAZEpzAiwP5hpJYUoCRB6lSAdpiH0OmDxptcTi+GmBTjUmG4vxTkKEHodwbjctAD7g+n2UlwEAUJvBDTPIYReT0De9HoCMtyMAIcaM62kEAUBQq8CIlOYEWB/MNNKClESIPQqQTpMQ+h1wOJNrycWw00LcKgx3V6KcxQg9DqCcblpAfYH0+2luAgChN4IaJ5DCL2egLzp9QRkuBkBDjVmWkkhCgKEXgVEpjAjwP5gppUUoiRA6FWCdJiG0OuAxZteTyyGmxbgUGO6vRTnKEDodQTjctMC7A+m20txEQQIvRHQPIcQej0BedPrCchwMwIcasy0kkIUBAi9CohMYUaA/cFMKylESYDQqwTpMA2h1wGLN72eWAw3LcChxnR7Kc5RgNDrCMblpgXYH0y3l+IiCBB6I6B5DiH0egLyptcTkOFmBDjUmGklhSgIEHoVEJnCjAD7g5lWUoiSAKFXCdJhGkKvAxZvej2xGG5agEON6fZSnKMAodcRjMtNC7A/mG4vxUUQIPRGQPMcQuj1BORNrycgw80IcKgx00oKURAg9CogMoUZAfYHM62kECUBQq8SpMM0hF4HLN70emIx3LQAhxrT7aU4RwFCryMYl5sWYH8w3V6KiyBA6I2A5jmE0OsJyJteT0CGmxHgUGOmlRSiIEDoVUBkCjMC7A9mWkkhSgKEXiVIh2kIvQ5YvOn1xGK4aQEONabbS3GOAoReRzAuNy3A/mC6vRQXQYDQGwHNcwih1xOQN72egAw3I8ChxkwrKURBgNCrgMgUZgTYH8y0kkKUBAi9SpAO0xB6HbB40+uJxXDTAhxqTLeX4hwFCL2OYFxuWoD9wXR7KS6CAKE3AprnEEKvJyBvej0BGW5GgEONmVZSiIIAoVcBkSnMCLA/mGklhSgJEHqVIB2mIfQ6YPGm1xOL4aYFONSYbi/FOQoQeh3BuNy0APuD6fZSXAQBQm8ENM8hhF5PQN70egIy3IwAhxozraQQBQFCrwIiU5gRYH8w00oKURIg9CpBOkxD6HXA4k2vJxbDTQtwqDHdXopzFCD0OoJxuWkB9gfT7aW4CAKE3ghonkMIvZ6AvOn1BGS4GQEONWZaSSEKAoReBUSmMCPA/mCmlRSiJEDoVYJ0mIbQ64DFm15PLIabFuBQY7q9FOcoQOh1BONy0wLsD6bbS3ERBAi9EdA8hxB6PQF50+sJyHAzAhxqzLSSQhQECL0KiExhRoD9wUwrKURJgNCrBOkwDaHXAYs3vZ5YDDctwKHGdHspzlGA0OsIxuWmBdgfTLeX4iIIEHojoHkOIfR6AvKm1xOQ4WYEONSYaSWFKAgQehUQmcKMAPuDmVZSiJIAoVcJ0mEaQq8DFm96PbEYblqAQ43p9lKcowCh1xGMy00LsD+Ybi/FRRAg9EZA8xxC6PUE5E2vJyDDzQhwqDHTSgpRECD0KiAyhRkB9gczraQQJQFCrxKkwzSEXgcs3vR6YjHctACHGtPtpThHAUKvIxiXmxZgfzDdXoqLIEDojYDmOYTQ6wnIm15PQIabEeBQY6aVFKIgQOhVQGQKMwLsD2ZaSSFKAoReJUiHaQi9Dli86fXEYrhpAQ41pttLcY4ChF5HMC43LcD+YLq9FBdBgNAbAc1zCKHXE5A3vZ6ADDcjwKHGTCspREGA0KuAyBRmBNgfzLSSQpQECL1KkA7TEHodsHjT64nFcNMCHGpMt5fiHAUIvY5gXG5agP3BdHspLoIAoTcCmucQQq8nIG96PQEZbkaAQ42ZVlKIggChVwGRKcwIsD+YaSWFKAkQepUgHaYh9Dpg8abXE4vhpgU41JhuL8U5ChB6HcG43LQA+4Pp9lJcBAFCbwQ0zyGEXk9A3vR6AjLcjACHGjOtpBAFAUKvAiJTmBFgfzDTSgpREiD0KkE6TEPodcDiTa8nFsNNC3CoMd1einMUIPQ6gnG5aQH2B9PtpbgIAoTeCGieQwi9noC86fUEZLgZAQ41ZlpJIQoChF4FRKYwI8D+YKaVFKIkQOhVgnSYhtDrgMWbXk8shpsW4FBjur0U5yhA6HUE43LTAuwPpttLcREECL0R0DyHEHo9AXnT6wnIcDMCHGrMtJJCFAQIvQqITGFGgP3BTCspREmA0KsE6TANodcBize9nlgMNy3AocZ0eynOUYDQ6wjG5aYF2B9Mt5fiIggQeiOgeQ4h9HoC8qbXE5DhZgQ41JhpJYUoCBB6FRCZwowA+4OZVlKIkgChVwnSYRpCrwMWb3o9sRhuWoBDjen2UpyjAKHXEYzLTQuwP5huL8VFECD0RkDzHELo9QTkTa8nIMPNCHCoMdNKClEQIPQqIDKFGQH2BzOtpBAlAUKvEqTDNIReByze9HpiMdy0AIca0+2lOEcBQq8jGJebFmB/MN1eiosgQOiNgOY5JGtDb/6adbK5oEBq1qjuRcibXi8+BhsS4FBjqJmU4i1A6PUmZAJDAuwPhppJKSoChF4VRqdJsi70rlu/Qbr1vV/mvPxOCHVg08YytG9n2aVWjRLhZi94Wzr3HLLdv3t71iipWKG8EHqdnjcuNizAocZwcynNWYDQ60zGAMMC7A+Gm0tpkQQIvZHYvAZlXegdPeEZmTxtnowf2kMqV6ogV940SBo2qCd9brykRMgXFrwlN985SqaM6l3s3zfYvY7k5OQQer0ePwZbEuBQY6mb1OIrQOj1FWS8JQH2B0vdpBYNAUKvhqLbHFkXett1uE1aHXOodDjvlFBq5rzX5YZew+XDuQ+GIXbbnyD09h4wThY8ObREWd70uj1wXG1XgEON3d5SmbsAodfdjBF2Bdgf7PaWyqIJEHqjufmMyrrQe2jrjtK326Vh8A1+Pv78Gznz8l7yyrRhUqN61RJD77U9h0qbVi2lYsUK0qJ5k3Bsuby88FpCr8/jx1hLAhxqLHWTWnwFCL2+goy3JMD+YKmb1KIhQOjVUHSbw0zoXfzDz/LM7Nd2WP35fz9BKlUsL82ObS/D77pejj6ieXjtl998L6dd3ENeeGyA1Ku783bjP/j06/BtcBCIFy9dJpOenivntj1eelx7QXhtYaEbOFcjYFWg6Bcl+L8Jqx2mLhcB/u/BRYtrrQvwfw/WO0x9rgIl/HKp6xRc7yhgJvR++91SefSpOTss/5pL2kqVypUkeNN7x02XyQlHtwivLe1N77YTPjHjRel5z1h5b/aY8G3vkuXrHcm5HAGbAtUqlRPJyZE16zfZLJCqEHAQqFercng1e4QDGpeaFWB/MNtaCosoULRHRBzOsAgCZkJvqrUHn+k98djD5LJzTw6HlPaZ3m3nXbDwA+nYbYC8NfMBqVSxAr/enCo815kX4NfXzLeYAh0E+PVmBywuNS/A/mC+xRToKMCvNzuCKVyedaF31CPTZcr0+eG3N1epXFE6dhtY7Nubx016ToI/UzR+aPeQd8LU2dKk8R7SdJ8/yqr8NdL19pFSvlyejB3ULfz3fKZX4SlkChMCHGpMtJEilAQIvUqQTGNCgP3BRBspQlGA0KuImeJUWRd6167bIF1uHyEvvvZeSNSsSUMZese1UmeXncJ/7jf8UZk0bZ688ezI8J8H3j9JxkycsZUz+Lu+/Xp2lPr1ahN6U3zIuCw7BDjUZEefqTI1AUJvak5clR0C7A/Z0WeqTF2A0Ju6ldaVWRd6i+BW5a+VTZs2yy61apRqueGXjfLTspVSvWoV2alGtWLX86a3VD4uyBIBDjVZ0mjKTEmA0JsSExdliQD7Q5Y0mjJTFiD0pkyldmHWhl41QSZCAAEEEEAAAQQQQAABBBBIrAChN7GtYWEIIIAAAggggAACCCCAAAK+AoReX0HGI4AAAggggAACCCCAAAIIJFaA0Kvcmi1bCqWwsFDy8nKVZ2Y6BJIr8PPyVeHfwQ6+EZ0fBBAQyV+zTjYXFEjNGtXhQCBrBHjus6bVFOohEOSEgi1bpFxenscsDHUVIPS6iv3O9cFD3GvAuPCK3l3aK87MVAgkU2DR90vDP/v17XdLwwWecdJf5dYbLgr/rFdJP3cPmygPTZ5Z7F8d3Gxvefi+HskskFUh4Ciwbv0G6db3fpnz8jvhyOAb/4f27ZzSlyY63orLEUiMgOtzH/xpyM49h2y3/rdnjZKKFconpi4WgkBZCEyb9YoMGjVZ5kweVBbTM+cOBAi9So/GzHmvS9/B42X5ynxpd8rRhF4lV6ZJtsDlXftLtaqV5Y6bOsgPPy6Tf1zRW269/kI59YQjS1z4v+6bIP9d/KPceNU5W/99xYrlZdfatZJdKKtDIEWB0ROekcnT5oV/C75ypQpy5U2Div0t+BSn4TIEMkrA9bl/YcFbcvOdo2TKqN7F6mywex3JycnJqNpZLAKpCgQvCjp06S/fLflJ6tauSehNFU7pOkKvEuS69b/I6jVrZdADk6VSxQqEXiVXpkmuQPBnv448tVP4ljZ4Wxv83HHvePnhx+Xh374u6ScIvStXr5F/db88uYWxMgQ8BNp1uE1aHXOodDjvlHCW4D+I3tBruHw490EO8x6uDE22gOtzH4Te3gPGyYInhya7MFaHgKJA8JGX4ONgc156R0ZPmE7oVbRNZSpCbypKDtfcPughKSgoIPQ6mHFpZgp8+c33ctrFPWTe44Ol9s47hUWMnzJLnpr58nb/9b6owiD0zpr/hhx+SNPws47H/eUQ+dOB+2QmAKtGoASBQ1t3lL7dLg2Db/Dz8effyJmX95JXpg2TGtWrYoaASQHX5z4Ivdf2HCptWrWUihUrSIvmTcL/m+EzjiYfD4raRuDZOQul34hHCb0xPxmE3lLA33r/c3n7g89LvCo4tAe/yvzbH0JvzE8wtysTgVSe+3c+/ELOv/qOYof5SdPmyciHntrh/0cefI7lm+9+CD+z9eFnX0vwua6Bva6SVsccViZ1MPwZ+b0AAAyNSURBVCkCcQoE3+vQ7Nj2Mvyu6+XoI5qHty76j0MvPDZA6tXdOc7lcC8EYhGI8tx/8OnX4W9BBP8haPHSZTLp6blybtvjpce1F8SyZm6CQDoFCL3p0Sf0luK+YOH78sqbH5V4Va2dqm/9FbaiCwi96XmQuauuQCrPfdFhfv4T9279kp7S3vRuu8qb7nxAVq7Kl5F3/1O3AGZDIE0CwRuvO266TE44ukW4At70pqkR3DZWAd/n/okZL0rPe8bKe7PH8LY31s5xs3QIEHrToS5C6FV2J/QqgzJdYgVK+kxvn0EPyY8/r9jhZ3q3LWbwqCkSvFUeP7R7YutkYQi4CASfbTzx2MPksnNPDofxmV4XPa7NVAHf537Bwg+kY7cB8tbMB8LvReEHAcsChN70dJfQq+ReULBFtmzZIn3vHS+bNxdIr39eLHl5eZKby7cQKhEzTQIFLuvST/5QrWr4Zqukb28OvsBnt113li4dzwpXH3zR22knHCkN6u8qn325SNpfd3cYDq644NQEVseSEHAXGPXIdJkyfX747c3B360O/qRXwwb1pM+Nl7hPxggEMkSgtOd+271gwtTZ0qTxHtJ0nz/Kqvw10vX2keGfuhs7qFuGVMwyEXAXCD4KEGSE5+a+Hv7JopkT+klObg6/3eBOGWkEoTcS2/aDgs+j9B7472L/IjjkBH+3lB8ErAp8vWhJeKgPvn4/+Dn9xL+E/8GnfPly4T+3veSW8MA/sFen8J/PuqJ3+Fneop/g+p7XX8h/2bf6gGRhXWvXbZAut4+QF197L6y+WZOG4W8+1Nnl1y974wcBiwKlPffb7gUD758kYybO2EoR/D3rfj07Sv16tS3yUBMCocB/vv5e2rTvUUwj+BOP/EWLeB4QQm88ztwFAdMCS39aEf693qpVKpVaZ/6adbJiVb7U3rlm+HdM+UHAokDw6/+bNm3e+nl3izVSEwLbCrg89xt+2Sg/LVsp1atWkZ1qVAMTAQQQKFMBQm+Z8jI5AggggAACCCCAAAIIIIBAOgUIvenU594IIIAAAggggAACCCCAAAJlKkDoLVNeJkcAAQQQQAABBBBAAAEEEEinAKE3nfrcGwEEEEAAAQQQQAABBBBAoEwFCL1lysvkCCCAAAIIIIAAAggggAAC6RQg9KZTn3sjgAACCCCAAAIIIIAAAgiUqQCht0x5mRwBBBBAAAEEEEAAAQQQQCCdAoTedOpzbwQQQAABBBBAAAEEEEAAgTIVIPSWKS+TI4AAAggggAACCCCAAAIIpFOA0JtOfe6NAAIIIIAAAggggAACCCBQpgKE3jLlZXIEEEAAAQQQQAABBBBAAIF0ChB606nPvRFAAAEEEEAAAQQQQAABBMpUgNBbprxMjgACCCCAAAIIIIAAAgggkE4BQm869bk3AggggAACCCCAAAIIIIBAmQoQesuUl8kRQAABBBBAAAEEEEAAAQTSKUDoTac+90YAAQQQyDiBSU/PlZfe+ECG9Omc0trXb9gol9xwt1zdvq20PLRZSmO4CAEEEEAAAQT0BAi9epbMhAACCCCQBQJDxjwuTz73ksyZPCilavPXrJPDT7lK+vW8Uk46/s8pjeEiBBBAAAEEENATIPTqWTITAggggEAWCBB6s6DJlIgAAgggYEqA0GuqnRSDAAIIIOArMO6x52TStLny07JV4VTN928s11xyhjRv2jj8521D72NPzZGX3/xQWhzYRKZMny9ffrtYjmt5sNz2z4tll1o1pOhNb6f2beWrbxfL/Fffk333aiAXtDtBTji6xdbl3tBruHz02dfy3ZKfpNZO1aXlYQfI9R3OlLq1a/qWxHgEEEAAAQSyWoDQm9Xtp3gEEEAAgW0Fho59QgoKtsg+jfaQgoICefjx5+WrRUtk7pRBUq1q5e1C78D7J8mYiTNkz/p1pW3ro8LQO23WK3JEi/1ldP+uW0NvcJ+Tjz9cDj5gb5n/6ruyYOEH8ur04fKHalXCJXTuOUQO2n8vqV+vjqxYuVrue3CqNNmrQTgHPwgggAACCCAQXYDQG92OkQgggAAChgU2FxTIylVr5I13P5Uut4+QicN7yoFNG5cYeqc+uyD8jG/58uVCkSA4j3zoaXnhsQFhUA4+09vj2gvk3LbHh/9++cp8Oer0a2Rgr07S6phDiyn+snGTrFiVL+Mnz5Jxk56T92ePlby8XMPSlIYAAggggEDZChB6y9aX2RFAAAEEMkzg0/8skv4jH5NX3/yo2MofHHSTHHbwviWG3pnz3pCZE/ttvX7BwvelY7eBMn5od9m7Yf0Sv8hq/2Mulq5XnS0X/+PEcNzMea+HQfnzr74rdt93nx+9NUxnGCXLRQABBBBAIBEChN5EtIFFIIAAAggkQWBV/lo58tRO4RvdzpecIY323E1Wr1krp7e/RVxC77xX3pVO3QfLhOE9pVGDeqWG3pff+FAu79pfTj/xL3LWacdK/d3qyOyX3pJe/ccJoTcJTwZrQAABBBDIZAFCbyZ3j7UjgAACCKgKBJ+z7dhtgDx8Xw85uNne4dyLvl8qrc/r5hR67xzyiDzyxPPy0lNDpVxeXqmhd/CoKTLqkeny7gtjpHy5vPC+wa9M33L3GEKvaoeZDAEEEEAgGwUIvdnYdWpGAAEEEChRoOiztm1atZSz2xwnS39eIfePnyaffPHt74beiU/Okb7dLpHd6u4is+a/KWMfnSHtTjlaendpv/WLrLb9O72//fXm4Budr7p5kHS98mxpcVAT+fizb8LPBQfr4U0vDysCCCCAAAJ+AoRePz9GI4AAAggYEwj+ZNGwcU/KuvUbwsqCXzl+8rmXZNzgm+TQg/YNw2jRF1cF/77o25uDPzMUhNTgJwjNwRdXVa1SSdasXS9/PvlKKSn03tjpHLnozFYSfGlW9ztHyTOzXwvHB3MF3+Q85+V3CL3Gni/KQQABBBCIX4DQG785d0QAAQQQSLhA8A3Ki3/4WXats7NUrlThd1cbhN7gi6xmPHy3LFuxWqpXq1LqmB1NuGr1WlmVv0Z237U239ic8GeE5SGAAAIIZI4AoTdzesVKEUAAAQQSKFAUen/77c0JXCZLQgABBBBAIGsFCL1Z23oKRwABBBDQEJgwdba8+uaHMvSOazWmYw4EEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBAi9yekFK0EAAQQQQAABBBBAAAEEEFAWIPQqgzIdAggggAACCCCAAAIIIIBAcgQIvcnpBStBAAEEEEAAAQQQQAABBBBQFiD0KoMyHQIIIIAAAggggAACCCCAQHIECL3J6QUrQQABBBBAAAEEEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBAi9yekFK0EAAQQQQAABBBBAAAEEEFAWIPQqgzIdAggggAACCCCAAAIIIIBAcgQIvcnpBStBAAEEEEAAAQQQQAABBBBQFiD0KoMyHQIIIIAAAggggAACCCCAQHIECL3J6QUrQQABBBBAAAEEEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBAi9yekFK0EAAQQQQAABBBBAAAEEEFAWIPQqgzIdAggggAACCCCAAAIIIIBAcgQIvcnpBStBAAEEEEAAAQQQQAABBBBQFiD0KoMyHQIIIIAAAggggAACCCCAQHIECL3J6QUrQQABBBBAAAEEEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBAi9yekFK0EAAQQQQAABBBBAAAEEEFAWIPQqgzIdAggggAACCCCAAAIIIIBAcgQIvcnpBStBAAEEEEAAAQQQQAABBBBQFiD0KoMyHQIIIIAAAggggAACCCCAQHIECL3J6QUrQQABBBBAAAEEEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBAi9yekFK0EAAQQQQAABBBBAAAEEEFAWIPQqgzIdAggggAACCCCAAAIIIIBAcgQIvcnpBStBAAEEEEAAAQQQQAABBBBQFiD0KoMyHQIIIIAAAggggAACCCCAQHIECL3J6QUrQQABBBBAAAEEEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBAi9yekFK0EAAQQQQAABBBBAAAEEEFAWIPQqgzIdAggggAACCCCAAAIIIIBAcgQIvcnpBStBAAEEEEAAAQQQQAABBBBQFiD0KoMyHQIIIIAAAggggAACCCCAQHIECL3J6QUrQQABBBBAAAEEEEAAAQQQUBYg9CqDMh0CCCCAAAIIIIAAAggggEByBP4/9/uiXmT/4pUAAAAASUVORK5CYII=",
      "text/html": [
       "<div>                            <div id=\"142e9b5a-3a3a-41b5-b08d-fbbf602f854e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"142e9b5a-3a3a-41b5-b08d-fbbf602f854e\")) {                    Plotly.newPlot(                        \"142e9b5a-3a3a-41b5-b08d-fbbf602f854e\",                        [{\"hovertemplate\":\"variable=diff\\u003cbr\\u003ealpha=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"diff\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"diff\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0],\"xaxis\":\"x\",\"y\":[-0.45932743533260445],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=tot\\u003cbr\\u003ealpha=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"tot\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"tot\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0],\"xaxis\":\"x\",\"y\":[0.9937816082330589],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"alpha\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('142e9b5a-3a3a-41b5-b08d-fbbf602f854e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = 13\n",
    "\n",
    "train_datasets = ['cities']\n",
    "val_dataset = 'sp_en_trans'\n",
    "\n",
    "ProbeClass = MMProbe\n",
    "\n",
    "# label tokens\n",
    "t_tok = tokenizer.encode('TRUE')[-1]\n",
    "f_tok = tokenizer.encode('FALSE')[-1]\n",
    "\n",
    "# get probe\n",
    "if ProbeClass == LRProbe or ProbeClass == MMProbe:\n",
    "    acts, labels = [], []\n",
    "    for dataset in train_datasets:\n",
    "        acts.append(collect_acts(dataset, model_size, layer).to(device))\n",
    "        labels.append(t.Tensor(pd.read_csv(f'datasets/{dataset}.csv')['label'].tolist()).to(device))\n",
    "    acts, labels = t.cat(acts), t.cat(labels)\n",
    "    probe = ProbeClass.from_data(acts, labels, device=device)\n",
    "elif ProbeClass == CCSProbe:\n",
    "    acts = collect_acts(train_datasets[0], model_size, layer, device=device)\n",
    "    neg_acts = collect_acts(train_datasets[1], model_size, layer, device=device)\n",
    "    labels = t.Tensor(pd.read_csv(f'datasets/{train_datasets[0]}.csv')['label'].tolist()).to(device)\n",
    "    probe = ProbeClass.from_data(acts, neg_acts, labels=labels, device=device)\n",
    "\n",
    "# get direction\n",
    "direction = probe.direction\n",
    "true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "direction = direction / direction.norm()\n",
    "diff = (true_mean - false_mean) @ direction\n",
    "direction = diff * direction\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "The Spanish word 'jirafa' means 'giraffe'. This statement is: TRUE\n",
    "The Spanish word 'escribir' means 'to write'. This statement is: TRUE\n",
    "The Spanish word 'diccionario' means 'dictionary'. This statement is: TRUE\n",
    "The Spanish word 'gato' means 'cat'. This statement is: TRUE\n",
    "The Spanish word 'aire' means 'silver'. This statement is: FALSE\"\"\"\n",
    "\n",
    "# make sure everything is clean going in\n",
    "for module in model.model.layers:\n",
    "    module._forward_hooks.clear()\n",
    "\n",
    "df_out = {'alpha' : [], 'diff' : [], 'tot' : []}\n",
    "\n",
    "# keep increasing alpha until things get worse\n",
    "# last_diff = -2\n",
    "# diff = -1\n",
    "# tot = 1\n",
    "# alpha = -1\n",
    "# while diff > last_diff and tot > .95:\n",
    "# last_diff = diff\n",
    "# alpha += 1\n",
    "alpha = 0\n",
    "# get probs\n",
    "df = pd.read_csv(f'datasets/{val_dataset}.csv')\n",
    "diffs, tots = [], []\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    if row['label'] == 0 and row['statement'] not in prompt:\n",
    "        input_ids = tokenizer(prompt + '\\n' +  row['statement'] + ' This statement is:', return_tensors='pt').input_ids.to(device)\n",
    "        period_tok = tokenizer.encode(\"'test'.\")[-1]\n",
    "        period_idxs = (input_ids == period_tok).nonzero(as_tuple=True)[1]\n",
    "        intervention_idx = period_idxs[5]\n",
    "\n",
    "        # intervened prob\n",
    "        def hook(module, input, output):\n",
    "            output[0][:,intervention_idx - 1, :] += direction * alpha\n",
    "            output[0][:, intervention_idx, :] += direction * alpha\n",
    "            return output\n",
    "        handle = model.model.layers[layer-1].register_forward_hook(hook)\n",
    "        probs = model(input_ids).logits[0,-1,:].softmax(-1)\n",
    "        handle.remove()\n",
    "\n",
    "        diffs.append(probs[t_tok].item() - probs[f_tok].item())\n",
    "        tots.append(probs[t_tok].item() + probs[f_tok].item())\n",
    "diff = sum(diffs) / len(diffs)\n",
    "tot = sum(tots) / len(tots)\n",
    "df_out['alpha'].append(alpha)\n",
    "df_out['diff'].append(diff)\n",
    "df_out['tot'].append(tot)\n",
    "\n",
    "# save results\n",
    "log = {\n",
    "    'train_datasets' : train_datasets,\n",
    "    'val_dataset' : val_dataset,\n",
    "    'layer' : layer,\n",
    "    'probe class' : ProbeClass.__name__,\n",
    "    'prompt' : prompt,\n",
    "    'results' : df_out,\n",
    "    'experiment' : 'false to true'\n",
    "}\n",
    "\n",
    "with open('experimental_outputs/label_change_intervention_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data.append(log)\n",
    "with open('experimental_outputs/label_change_intervention_results.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "px.line(pd.DataFrame(df_out), x='alpha', y=['diff', 'tot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True -> false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:01, 21.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     71\u001b[0m handle \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[layer\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mregister_forward_hook(hook)\n\u001b[0;32m---> 72\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     73\u001b[0m handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m     75\u001b[0m diffs\u001b[38;5;241m.\u001b[39mappend(probs[t_tok]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m probs[f_tok]\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/modeling_llama.py:820\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    817\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/modeling_llama.py:708\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    701\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    702\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    703\u001b[0m         hidden_states,\n\u001b[1;32m    704\u001b[0m         attention_mask,\n\u001b[1;32m    705\u001b[0m         position_ids,\n\u001b[1;32m    706\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/modeling_llama.py:424\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    421\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/modeling_llama.py:333\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    331\u001b[0m     kv_seq_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    332\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, seq_len\u001b[38;5;241m=\u001b[39mkv_seq_len)\n\u001b[0;32m--> 333\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/modeling_llama.py:187\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids)\u001b[0m\n\u001b[1;32m    185\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, 1, seq_len, dim]\u001b[39;00m\n\u001b[1;32m    186\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m--> 187\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layer = 10\n",
    "\n",
    "train_datasets = ['cities']\n",
    "val_dataset = 'sp_en_trans'\n",
    "\n",
    "ProbeClass = MMProbe\n",
    "\n",
    "# label tokens\n",
    "t_tok = tokenizer.encode('TRUE')[-1]\n",
    "f_tok = tokenizer.encode('FALSE')[-1]\n",
    "\n",
    "# get probe\n",
    "if ProbeClass == LRProbe or ProbeClass == MMProbe:\n",
    "    acts, labels = [], []\n",
    "    for dataset in train_datasets:\n",
    "        acts.append(collect_acts(dataset, model_size, layer).to(device))\n",
    "        labels.append(t.Tensor(pd.read_csv(f'datasets/{dataset}.csv')['label'].tolist()).to(device))\n",
    "    acts, labels = t.cat(acts), t.cat(labels)\n",
    "    probe = ProbeClass.from_data(acts, labels, device=device)\n",
    "elif ProbeClass == CCSProbe:\n",
    "    acts = collect_acts(train_datasets[0], model_size, layer, device=device)\n",
    "    neg_acts = collect_acts(train_datasets[1], model_size, layer, device=device)\n",
    "    labels = t.Tensor(pd.read_csv(f'datasets/{train_datasets[0]}.csv')['label'].tolist()).to(device)\n",
    "    probe = ProbeClass.from_data(acts, neg_acts, labels=labels, device=device)\n",
    "\n",
    "# get direction\n",
    "direction = probe.direction\n",
    "true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "direction = direction / direction.norm()\n",
    "diff = (true_mean - false_mean) @ direction\n",
    "direction = diff * direction\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "The Spanish word 'jirafa' means 'giraffe'. This statement is: TRUE\n",
    "The Spanish word 'escribir' means 'to write'. This statement is: TRUE\n",
    "The Spanish word 'diccionario' means 'dictionary'. This statement is: TRUE\n",
    "The Spanish word 'gato' means 'cat'. This statement is: TRUE\n",
    "The Spanish word 'aire' means 'silver'. This statement is: FALSE\"\"\"\n",
    "\n",
    "# make sure everything is clean going in\n",
    "for module in model.model.layers:\n",
    "    module._forward_hooks.clear()\n",
    "\n",
    "df_out = {'alpha' : [], 'diff' : [], 'tot' : []}\n",
    "\n",
    "# keep decreasing alpha until things get worse\n",
    "# last_diff = 2\n",
    "# diff = 1\n",
    "# tot = 1\n",
    "# alpha = -1\n",
    "# while diff < last_diff and tot > .95:\n",
    "    # last_diff = diff\n",
    "    # alpha += 1\n",
    "    # get probs\n",
    "alpha = 6\n",
    "df = pd.read_csv(f'datasets/{val_dataset}.csv')\n",
    "diffs, tots = [], []\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    if row['label'] == 1 and row['statement'] not in prompt:\n",
    "        input_ids = tokenizer(prompt + '\\n' +  row['statement'] + ' This statement is:', return_tensors='pt').input_ids.to(device)\n",
    "        period_tok = tokenizer.encode(\"'test'.\")[-1]\n",
    "        period_idxs = (input_ids == period_tok).nonzero(as_tuple=True)[1]\n",
    "        intervention_idx = period_idxs[5]\n",
    "\n",
    "        # intervened prob\n",
    "        def hook(module, input, output):\n",
    "            output[0][:,intervention_idx - 1, :] -= direction * alpha\n",
    "            output[0][:, intervention_idx, :] -= direction * alpha\n",
    "            return output\n",
    "        handle = model.model.layers[layer-1].register_forward_hook(hook)\n",
    "        probs = model(input_ids).logits[0,-1,:].softmax(-1)\n",
    "        handle.remove()\n",
    "\n",
    "        diffs.append(probs[t_tok].item() - probs[f_tok].item())\n",
    "        tots.append(probs[t_tok].item() + probs[f_tok].item())\n",
    "diff = sum(diffs) / len(diffs)\n",
    "tot = sum(tots) / len(tots)\n",
    "df_out['alpha'].append(alpha)\n",
    "df_out['diff'].append(diff)\n",
    "df_out['tot'].append(tot)\n",
    "\n",
    "# save results\n",
    "log = {\n",
    "    'train_datasets' : train_datasets,\n",
    "    'val_dataset' : val_dataset,\n",
    "    'layer' : layer,\n",
    "    'probe class' : ProbeClass.__name__,\n",
    "    'prompt' : prompt,\n",
    "    'results' : df_out,\n",
    "    'experiment' : 'true to false'\n",
    "}\n",
    "\n",
    "with open('experimental_outputs/label_change_intervention_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data.append(log)\n",
    "with open('experimental_outputs/label_change_intervention_results.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "px.line(pd.DataFrame(df_out), x='alpha', y=['diff', 'tot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intervene all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "354it [00:18, 18.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6217546254568707 0.9912983856104702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layer = 14\n",
    "intervene_layers = range(8,15)\n",
    "alpha = 1 # zero for no intervention, 1 for intervention\n",
    "label_value = 1 # 1 if using true statements (true->false), 0 if false staetment (false->true)\n",
    "\n",
    "train_datasets = ['cities']\n",
    "val_dataset = 'sp_en_trans'\n",
    "\n",
    "ProbeClass = MMProbe\n",
    "\n",
    "# label tokens\n",
    "t_tok = tokenizer.encode('TRUE')[-1]\n",
    "f_tok = tokenizer.encode('FALSE')[-1]\n",
    "\n",
    "# get probe\n",
    "if ProbeClass == LRProbe or ProbeClass == MMProbe:\n",
    "    acts, labels = [], []\n",
    "    for dataset in train_datasets:\n",
    "        acts.append(collect_acts(dataset, model_size, layer).to(device))\n",
    "        labels.append(t.Tensor(pd.read_csv(f'datasets/{dataset}.csv')['label'].tolist()).to(device))\n",
    "    acts, labels = t.cat(acts), t.cat(labels)\n",
    "    probe = ProbeClass.from_data(acts, labels, device=device)\n",
    "elif ProbeClass == CCSProbe:\n",
    "    acts = collect_acts(train_datasets[0], model_size, layer, device=device)\n",
    "    neg_acts = collect_acts(train_datasets[1], model_size, layer, device=device)\n",
    "    labels = t.Tensor(pd.read_csv(f'datasets/{train_datasets[0]}.csv')['label'].tolist()).to(device)\n",
    "    probe = ProbeClass.from_data(acts, neg_acts, labels=labels, device=device)\n",
    "\n",
    "# get direction\n",
    "direction = probe.direction\n",
    "true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "direction = direction / direction.norm()\n",
    "diff = (true_mean - false_mean) @ direction\n",
    "direction = diff * direction\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "The Spanish word 'jirafa' means 'giraffe'. This statement is: TRUE\n",
    "The Spanish word 'escribir' means 'to write'. This statement is: TRUE\n",
    "The Spanish word 'diccionario' means 'dictionary'. This statement is: TRUE\n",
    "The Spanish word 'gato' means 'cat'. This statement is: TRUE\n",
    "The Spanish word 'aire' means 'silver'. This statement is: FALSE\"\"\"\n",
    "\n",
    "# make sure everything is clean going in\n",
    "for module in model.model.layers:\n",
    "    module._forward_hooks.clear()\n",
    "\n",
    "# get probs\n",
    "df = pd.read_csv(f'datasets/{val_dataset}.csv')\n",
    "diffs, tots = [], []\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    if row['label'] == label_value and row['statement'] not in prompt:\n",
    "        input_ids = tokenizer(prompt + '\\n' +  row['statement'] + ' This statement is:', return_tensors='pt').input_ids.to(device)\n",
    "        period_tok = tokenizer.encode(\"'test'.\")[-1]\n",
    "        period_idxs = (input_ids == period_tok).nonzero(as_tuple=True)[1]\n",
    "        intervention_idx = period_idxs[5]\n",
    "\n",
    "        # intervened prob\n",
    "        def hook(module, input, output):\n",
    "            if label_value == 1:\n",
    "                output[0][:,intervention_idx - 1, :] -= direction * alpha\n",
    "                output[0][:, intervention_idx, :] -= direction * alpha\n",
    "            else:\n",
    "                output[0][:,intervention_idx - 1, :] += direction * alpha\n",
    "                output[0][:, intervention_idx, :] += direction * alpha\n",
    "            return output\n",
    "        \n",
    "        handles = []\n",
    "        for layer in intervene_layers:\n",
    "            handle = model.model.layers[layer].register_forward_hook(hook)\n",
    "            handles.append(handle)\n",
    "        probs = model(input_ids).logits[0,-1,:].softmax(-1)\n",
    "        for handle in handles:\n",
    "            handle.remove()\n",
    "\n",
    "        diffs.append(probs[t_tok].item() - probs[f_tok].item())\n",
    "        tots.append(probs[t_tok].item() + probs[f_tok].item())\n",
    "diff = sum(diffs) / len(diffs)\n",
    "tot = sum(tots) / len(tots)\n",
    "print(diff, tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True -> False (intervene all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
